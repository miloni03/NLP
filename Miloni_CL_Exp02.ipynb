{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "cO1Nmf9G_eX8"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from nltk import word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OxvROtB-APjV",
        "outputId": "eadc75aa-0a4e-4cf1-bda7-4941bbc6ac90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s=\"National Science Day is celebrated on 28th February every year. The day is to commemorate the famous Indian Physicist Sir C.V. Raman’s discovery of the ‘Raman Effect.’ Moreover, Science Day is a day where people can learn about science and its impact on our lives. It can also be a way to get children excited about science and what they might want to do in the future. On Science Day, different events worldwide promote science and give people the opportunity to participate in hands-on experiments. BYJU’S essay on Science Day helps us know some notable achievements and the objectives of celebrating Science Day. The wonder of science is immeasurable, and we must respect the significant innovations. Science Day is an annual celebration of science and technology in India. National Science Day was first observed in 1987 in India. Moreover, Science Day is celebrated across the country in different sectors like schools, colleges, government offices, universities, etc. National Science Day is also celebrated in research institutes, medical colleges, and science institutes. Now, let us learn some objectives of celebrating Science Day by reading an essay on Science Day in English. Science Day is celebrated to spread awareness and a message about the importance of scientific theories and applications in everyday life. Science day essay in English explains to us, in brief, the objectives of celebrating Science Day. The objective of celebrating Science Day is to display the efforts, accomplishments and activities in the scientific field for human welfare. Moreover, science enthusiasts and scientists discuss theories of science in everyday life and methods to improve technologies\""
      ],
      "metadata": {
        "id": "IaRLaESwASgT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re \n",
        "def generate_ngrams(s,n):\n",
        "  s=re.sub(r'[^a-zA-Z0-9\\s]','',s)\n",
        "  s=s.lower()\n",
        "  tokens=[token for token in s.split(\" \") if token !=\"\"]\n",
        "  ngrams=zip(*[tokens[i:]for i in range(n)])\n",
        "  return [\" \".join(ngram) for ngram in ngrams],s\n",
        "bigram,s=generate_ngrams(s,n=2)"
      ],
      "metadata": {
        "id": "zhe3aJSQBU-3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1-36bqgqBklO",
        "outputId": "ce45bc99-df96-4b27-e87b-0d97c19d8049"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['national science', 'science day', 'day is', 'is celebrated', 'celebrated on', 'on 28th', '28th february', 'february every', 'every year', 'year the', 'the day', 'day is', 'is to', 'to commemorate', 'commemorate the', 'the famous', 'famous indian', 'indian physicist', 'physicist sir', 'sir cv', 'cv ramans', 'ramans discovery', 'discovery of', 'of the', 'the raman', 'raman effect', 'effect moreover', 'moreover science', 'science day', 'day is', 'is a', 'a day', 'day where', 'where people', 'people can', 'can learn', 'learn about', 'about science', 'science and', 'and its', 'its impact', 'impact on', 'on our', 'our lives', 'lives it', 'it can', 'can also', 'also be', 'be a', 'a way', 'way to', 'to get', 'get children', 'children excited', 'excited about', 'about science', 'science and', 'and what', 'what they', 'they might', 'might want', 'want to', 'to do', 'do in', 'in the', 'the future', 'future on', 'on science', 'science day', 'day different', 'different events', 'events worldwide', 'worldwide promote', 'promote science', 'science and', 'and give', 'give people', 'people the', 'the opportunity', 'opportunity to', 'to participate', 'participate in', 'in handson', 'handson experiments', 'experiments byjus', 'byjus essay', 'essay on', 'on science', 'science day', 'day helps', 'helps us', 'us know', 'know some', 'some notable', 'notable achievements', 'achievements and', 'and the', 'the objectives', 'objectives of', 'of celebrating', 'celebrating science', 'science day', 'day the', 'the wonder', 'wonder of', 'of science', 'science is', 'is immeasurable', 'immeasurable and', 'and we', 'we must', 'must respect', 'respect the', 'the significant', 'significant innovations', 'innovations science', 'science day', 'day is', 'is an', 'an annual', 'annual celebration', 'celebration of', 'of science', 'science and', 'and technology', 'technology in', 'in india', 'india national', 'national science', 'science day', 'day was', 'was first', 'first observed', 'observed in', 'in 1987', '1987 in', 'in india', 'india moreover', 'moreover science', 'science day', 'day is', 'is celebrated', 'celebrated across', 'across the', 'the country', 'country in', 'in different', 'different sectors', 'sectors like', 'like schools', 'schools colleges', 'colleges government', 'government offices', 'offices universities', 'universities etc', 'etc national', 'national science', 'science day', 'day is', 'is also', 'also celebrated', 'celebrated in', 'in research', 'research institutes', 'institutes medical', 'medical colleges', 'colleges and', 'and science', 'science institutes', 'institutes now', 'now let', 'let us', 'us learn', 'learn some', 'some objectives', 'objectives of', 'of celebrating', 'celebrating science', 'science day', 'day by', 'by reading', 'reading an', 'an essay', 'essay on', 'on science', 'science day', 'day in', 'in english', 'english science', 'science day', 'day is', 'is celebrated', 'celebrated to', 'to spread', 'spread awareness', 'awareness and', 'and a', 'a message', 'message about', 'about the', 'the importance', 'importance of', 'of scientific', 'scientific theories', 'theories and', 'and applications', 'applications in', 'in everyday', 'everyday life', 'life science', 'science day', 'day essay', 'essay in', 'in english', 'english explains', 'explains to', 'to us', 'us in', 'in brief', 'brief the', 'the objectives', 'objectives of', 'of celebrating', 'celebrating science', 'science day', 'day the', 'the objective', 'objective of', 'of celebrating', 'celebrating science', 'science day', 'day is', 'is to', 'to display', 'display the', 'the efforts', 'efforts accomplishments', 'accomplishments and', 'and activities', 'activities in', 'in the', 'the scientific', 'scientific field', 'field for', 'for human', 'human welfare', 'welfare moreover', 'moreover science', 'science enthusiasts', 'enthusiasts and', 'and scientists', 'scientists discuss', 'discuss theories', 'theories of', 'of science', 'science in', 'in everyday', 'everyday life', 'life and', 'and methods', 'methods to', 'to improve', 'improve technologies']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fdist=nltk.FreqDist(bigram)\n",
        "print(fdist)\n",
        "word_freq_pairs=[]\n",
        "for k,v in fdist.items():\n",
        "  word_freq_pairs.append((k.split()[0],k.split()[1],v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "k61dvc8jCEbX",
        "outputId": "fc30a13b-b255-4838-8719-580e665cbc5f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<FreqDist with 211 samples and 263 outcomes>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_freq_pairs[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sp8Ct_toIayi",
        "outputId": "0eeaf12d-3efb-4a17-c8c5-701f1581faa0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('national', 'science', 3),\n",
              " ('science', 'day', 15),\n",
              " ('day', 'is', 8),\n",
              " ('is', 'celebrated', 3),\n",
              " ('celebrated', 'on', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#co-occurance matrix\n",
        "import pandas as pd\n",
        "def bigran_frequency_dataframe (bigram_freq_pairs):\n",
        "  words = sorted(set([pair[0] for pair in bigram_freq_pairs] + [pair[1] for pair in bigram_freq_pairs]))\n",
        "  df = pd.DataFrame(columns=words, index=words)\n",
        "  for pair in bigram_freq_pairs:\n",
        "    df.at[pair[0], pair[1]] = pair[2]\n",
        "  df.fillna(0, inplace=True)\n",
        "  return df\n",
        "\n",
        "df = bigran_frequency_dataframe (word_freq_pairs)\n"
      ],
      "metadata": {
        "id": "-2YIyv89Bmuu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "sNC2exDODQis",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "20d1dd5f-3061-4cb2-c2fb-2add74a14341"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 1987  28th  a  about  accomplishments  achievements  across  \\\n",
              "1987                0     0  0      0                0             0       0   \n",
              "28th                0     0  0      0                0             0       0   \n",
              "a                   0     0  0      0                0             0       0   \n",
              "about               0     0  0      0                0             0       0   \n",
              "accomplishments     0     0  0      0                0             0       0   \n",
              "\n",
              "                 activities  also  an  ...  want  was  way  we  welfare  what  \\\n",
              "1987                      0     0   0  ...     0    0    0   0        0     0   \n",
              "28th                      0     0   0  ...     0    0    0   0        0     0   \n",
              "a                         0     0   0  ...     0    0    1   0        0     0   \n",
              "about                     0     0   0  ...     0    0    0   0        0     0   \n",
              "accomplishments           0     0   0  ...     0    0    0   0        0     0   \n",
              "\n",
              "                 where  wonder  worldwide  year  \n",
              "1987                 0       0          0     0  \n",
              "28th                 0       0          0     0  \n",
              "a                    0       0          0     0  \n",
              "about                0       0          0     0  \n",
              "accomplishments      0       0          0     0  \n",
              "\n",
              "[5 rows x 128 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d9d0ced-aa4a-4c86-b545-29bd8dc7aeec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1987</th>\n",
              "      <th>28th</th>\n",
              "      <th>a</th>\n",
              "      <th>about</th>\n",
              "      <th>accomplishments</th>\n",
              "      <th>achievements</th>\n",
              "      <th>across</th>\n",
              "      <th>activities</th>\n",
              "      <th>also</th>\n",
              "      <th>an</th>\n",
              "      <th>...</th>\n",
              "      <th>want</th>\n",
              "      <th>was</th>\n",
              "      <th>way</th>\n",
              "      <th>we</th>\n",
              "      <th>welfare</th>\n",
              "      <th>what</th>\n",
              "      <th>where</th>\n",
              "      <th>wonder</th>\n",
              "      <th>worldwide</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28th</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>about</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accomplishments</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 128 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d9d0ced-aa4a-4c86-b545-29bd8dc7aeec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d9d0ced-aa4a-4c86-b545-29bd8dc7aeec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d9d0ced-aa4a-4c86-b545-29bd8dc7aeec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = bigran_frequency_dataframe (word_freq_pairs[:5])"
      ],
      "metadata": {
        "id": "mtklehsSJBh7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "96-jEFTPJaXx",
        "outputId": "3bbdae89-115b-48fa-e0c1-894fb48fb3c0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            celebrated  day  is  national  on  science\n",
              "celebrated           0    0   0         0   1        0\n",
              "day                  0    0   8         0   0        0\n",
              "is                   3    0   0         0   0        0\n",
              "national             0    0   0         0   0        3\n",
              "on                   0    0   0         0   0        0\n",
              "science              0   15   0         0   0        0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7fb7502-2fd9-444b-ab0e-97a0c09f4865\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>celebrated</th>\n",
              "      <th>day</th>\n",
              "      <th>is</th>\n",
              "      <th>national</th>\n",
              "      <th>on</th>\n",
              "      <th>science</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>celebrated</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>day</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>national</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>on</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>science</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7fb7502-2fd9-444b-ab0e-97a0c09f4865')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7fb7502-2fd9-444b-ab0e-97a0c09f4865 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7fb7502-2fd9-444b-ab0e-97a0c09f4865');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bNKre29nTK1Y",
        "outputId": "a38732aa-dcb9-4d2c-82fd-8501d974b9c6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['national science',\n",
              " 'science day',\n",
              " 'day is',\n",
              " 'is celebrated',\n",
              " 'celebrated on',\n",
              " 'on 28th',\n",
              " '28th february',\n",
              " 'february every',\n",
              " 'every year',\n",
              " 'year the',\n",
              " 'the day',\n",
              " 'day is',\n",
              " 'is to',\n",
              " 'to commemorate',\n",
              " 'commemorate the',\n",
              " 'the famous',\n",
              " 'famous indian',\n",
              " 'indian physicist',\n",
              " 'physicist sir',\n",
              " 'sir cv',\n",
              " 'cv ramans',\n",
              " 'ramans discovery',\n",
              " 'discovery of',\n",
              " 'of the',\n",
              " 'the raman',\n",
              " 'raman effect',\n",
              " 'effect moreover',\n",
              " 'moreover science',\n",
              " 'science day',\n",
              " 'day is',\n",
              " 'is a',\n",
              " 'a day',\n",
              " 'day where',\n",
              " 'where people',\n",
              " 'people can',\n",
              " 'can learn',\n",
              " 'learn about',\n",
              " 'about science',\n",
              " 'science and',\n",
              " 'and its',\n",
              " 'its impact',\n",
              " 'impact on',\n",
              " 'on our',\n",
              " 'our lives',\n",
              " 'lives it',\n",
              " 'it can',\n",
              " 'can also',\n",
              " 'also be',\n",
              " 'be a',\n",
              " 'a way',\n",
              " 'way to',\n",
              " 'to get',\n",
              " 'get children',\n",
              " 'children excited',\n",
              " 'excited about',\n",
              " 'about science',\n",
              " 'science and',\n",
              " 'and what',\n",
              " 'what they',\n",
              " 'they might',\n",
              " 'might want',\n",
              " 'want to',\n",
              " 'to do',\n",
              " 'do in',\n",
              " 'in the',\n",
              " 'the future',\n",
              " 'future on',\n",
              " 'on science',\n",
              " 'science day',\n",
              " 'day different',\n",
              " 'different events',\n",
              " 'events worldwide',\n",
              " 'worldwide promote',\n",
              " 'promote science',\n",
              " 'science and',\n",
              " 'and give',\n",
              " 'give people',\n",
              " 'people the',\n",
              " 'the opportunity',\n",
              " 'opportunity to',\n",
              " 'to participate',\n",
              " 'participate in',\n",
              " 'in handson',\n",
              " 'handson experiments',\n",
              " 'experiments byjus',\n",
              " 'byjus essay',\n",
              " 'essay on',\n",
              " 'on science',\n",
              " 'science day',\n",
              " 'day helps',\n",
              " 'helps us',\n",
              " 'us know',\n",
              " 'know some',\n",
              " 'some notable',\n",
              " 'notable achievements',\n",
              " 'achievements and',\n",
              " 'and the',\n",
              " 'the objectives',\n",
              " 'objectives of',\n",
              " 'of celebrating',\n",
              " 'celebrating science',\n",
              " 'science day',\n",
              " 'day the',\n",
              " 'the wonder',\n",
              " 'wonder of',\n",
              " 'of science',\n",
              " 'science is',\n",
              " 'is immeasurable',\n",
              " 'immeasurable and',\n",
              " 'and we',\n",
              " 'we must',\n",
              " 'must respect',\n",
              " 'respect the',\n",
              " 'the significant',\n",
              " 'significant innovations',\n",
              " 'innovations science',\n",
              " 'science day',\n",
              " 'day is',\n",
              " 'is an',\n",
              " 'an annual',\n",
              " 'annual celebration',\n",
              " 'celebration of',\n",
              " 'of science',\n",
              " 'science and',\n",
              " 'and technology',\n",
              " 'technology in',\n",
              " 'in india',\n",
              " 'india national',\n",
              " 'national science',\n",
              " 'science day',\n",
              " 'day was',\n",
              " 'was first',\n",
              " 'first observed',\n",
              " 'observed in',\n",
              " 'in 1987',\n",
              " '1987 in',\n",
              " 'in india',\n",
              " 'india moreover',\n",
              " 'moreover science',\n",
              " 'science day',\n",
              " 'day is',\n",
              " 'is celebrated',\n",
              " 'celebrated across',\n",
              " 'across the',\n",
              " 'the country',\n",
              " 'country in',\n",
              " 'in different',\n",
              " 'different sectors',\n",
              " 'sectors like',\n",
              " 'like schools',\n",
              " 'schools colleges',\n",
              " 'colleges government',\n",
              " 'government offices',\n",
              " 'offices universities',\n",
              " 'universities etc',\n",
              " 'etc national',\n",
              " 'national science',\n",
              " 'science day',\n",
              " 'day is',\n",
              " 'is also',\n",
              " 'also celebrated',\n",
              " 'celebrated in',\n",
              " 'in research',\n",
              " 'research institutes',\n",
              " 'institutes medical',\n",
              " 'medical colleges',\n",
              " 'colleges and',\n",
              " 'and science',\n",
              " 'science institutes',\n",
              " 'institutes now',\n",
              " 'now let',\n",
              " 'let us',\n",
              " 'us learn',\n",
              " 'learn some',\n",
              " 'some objectives',\n",
              " 'objectives of',\n",
              " 'of celebrating',\n",
              " 'celebrating science',\n",
              " 'science day',\n",
              " 'day by',\n",
              " 'by reading',\n",
              " 'reading an',\n",
              " 'an essay',\n",
              " 'essay on',\n",
              " 'on science',\n",
              " 'science day',\n",
              " 'day in',\n",
              " 'in english',\n",
              " 'english science',\n",
              " 'science day',\n",
              " 'day is',\n",
              " 'is celebrated',\n",
              " 'celebrated to',\n",
              " 'to spread',\n",
              " 'spread awareness',\n",
              " 'awareness and',\n",
              " 'and a',\n",
              " 'a message',\n",
              " 'message about',\n",
              " 'about the',\n",
              " 'the importance',\n",
              " 'importance of',\n",
              " 'of scientific',\n",
              " 'scientific theories',\n",
              " 'theories and',\n",
              " 'and applications',\n",
              " 'applications in',\n",
              " 'in everyday',\n",
              " 'everyday life',\n",
              " 'life science',\n",
              " 'science day',\n",
              " 'day essay',\n",
              " 'essay in',\n",
              " 'in english',\n",
              " 'english explains',\n",
              " 'explains to',\n",
              " 'to us',\n",
              " 'us in',\n",
              " 'in brief',\n",
              " 'brief the',\n",
              " 'the objectives',\n",
              " 'objectives of',\n",
              " 'of celebrating',\n",
              " 'celebrating science',\n",
              " 'science day',\n",
              " 'day the',\n",
              " 'the objective',\n",
              " 'objective of',\n",
              " 'of celebrating',\n",
              " 'celebrating science',\n",
              " 'science day',\n",
              " 'day is',\n",
              " 'is to',\n",
              " 'to display',\n",
              " 'display the',\n",
              " 'the efforts',\n",
              " 'efforts accomplishments',\n",
              " 'accomplishments and',\n",
              " 'and activities',\n",
              " 'activities in',\n",
              " 'in the',\n",
              " 'the scientific',\n",
              " 'scientific field',\n",
              " 'field for',\n",
              " 'for human',\n",
              " 'human welfare',\n",
              " 'welfare moreover',\n",
              " 'moreover science',\n",
              " 'science enthusiasts',\n",
              " 'enthusiasts and',\n",
              " 'and scientists',\n",
              " 'scientists discuss',\n",
              " 'discuss theories',\n",
              " 'theories of',\n",
              " 'of science',\n",
              " 'science in',\n",
              " 'in everyday',\n",
              " 'everyday life',\n",
              " 'life and',\n",
              " 'and methods',\n",
              " 'methods to',\n",
              " 'to improve',\n",
              " 'improve technologies']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_bigrams = len(bigram)\n",
        "print('Count of Total Bigrams ',number_of_bigrams) \n",
        "\n",
        "h1 = s.count('human')\n",
        "print (f'Human: {h1}')\n",
        "\n",
        "w1 = bigram. count (\"human welfare\")\n",
        "print(f'Human Welfare: {w1}')\n",
        "\n",
        "print (f\"P(welfare | human): {w1/h1:.3f}\")\n",
        "\n",
        "print(f'P(Human): {w1/number_of_bigrams:.3f}')\n",
        "print(f'P(Welfare): {h1/number_of_bigrams:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "S1dBZYXhJEWy",
        "outputId": "384dea1c-b2e2-44ab-e563-5c30a26e51b1"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of Total Bigrams  263\n",
            "Human: 1\n",
            "Human Welfare: 1\n",
            "P(welfare | human): 1.000\n",
            "P(Human): 0.004\n",
            "P(Welfare): 0.004\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.index.to_list()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OvmOSG16UIZ1",
        "outputId": "9070af4d-1457-4078-9b02-a262f44f5bb7"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1987',\n",
              " '28th',\n",
              " 'a',\n",
              " 'about',\n",
              " 'accomplishments',\n",
              " 'achievements',\n",
              " 'across',\n",
              " 'activities',\n",
              " 'also',\n",
              " 'an',\n",
              " 'and',\n",
              " 'annual',\n",
              " 'applications',\n",
              " 'awareness',\n",
              " 'be',\n",
              " 'brief',\n",
              " 'by',\n",
              " 'byjus',\n",
              " 'can',\n",
              " 'celebrated',\n",
              " 'celebrating',\n",
              " 'celebration',\n",
              " 'children',\n",
              " 'colleges',\n",
              " 'commemorate',\n",
              " 'country',\n",
              " 'cv',\n",
              " 'day',\n",
              " 'different',\n",
              " 'discovery',\n",
              " 'discuss',\n",
              " 'display',\n",
              " 'do',\n",
              " 'effect',\n",
              " 'efforts',\n",
              " 'english',\n",
              " 'enthusiasts',\n",
              " 'essay',\n",
              " 'etc',\n",
              " 'events',\n",
              " 'every',\n",
              " 'everyday',\n",
              " 'excited',\n",
              " 'experiments',\n",
              " 'explains',\n",
              " 'famous',\n",
              " 'february',\n",
              " 'field',\n",
              " 'first',\n",
              " 'for',\n",
              " 'future',\n",
              " 'get',\n",
              " 'give',\n",
              " 'government',\n",
              " 'handson',\n",
              " 'helps',\n",
              " 'human',\n",
              " 'immeasurable',\n",
              " 'impact',\n",
              " 'importance',\n",
              " 'improve',\n",
              " 'in',\n",
              " 'india',\n",
              " 'indian',\n",
              " 'innovations',\n",
              " 'institutes',\n",
              " 'is',\n",
              " 'it',\n",
              " 'its',\n",
              " 'know',\n",
              " 'learn',\n",
              " 'let',\n",
              " 'life',\n",
              " 'like',\n",
              " 'lives',\n",
              " 'medical',\n",
              " 'message',\n",
              " 'methods',\n",
              " 'might',\n",
              " 'moreover',\n",
              " 'must',\n",
              " 'national',\n",
              " 'notable',\n",
              " 'now',\n",
              " 'objective',\n",
              " 'objectives',\n",
              " 'observed',\n",
              " 'of',\n",
              " 'offices',\n",
              " 'on',\n",
              " 'opportunity',\n",
              " 'our',\n",
              " 'participate',\n",
              " 'people',\n",
              " 'physicist',\n",
              " 'promote',\n",
              " 'raman',\n",
              " 'ramans',\n",
              " 'reading',\n",
              " 'research',\n",
              " 'respect',\n",
              " 'schools',\n",
              " 'science',\n",
              " 'scientific',\n",
              " 'scientists',\n",
              " 'sectors',\n",
              " 'significant',\n",
              " 'sir',\n",
              " 'some',\n",
              " 'spread',\n",
              " 'technologies',\n",
              " 'technology',\n",
              " 'the',\n",
              " 'theories',\n",
              " 'they',\n",
              " 'to',\n",
              " 'universities',\n",
              " 'us',\n",
              " 'want',\n",
              " 'was',\n",
              " 'way',\n",
              " 'we',\n",
              " 'welfare',\n",
              " 'what',\n",
              " 'where',\n",
              " 'wonder',\n",
              " 'worldwide',\n",
              " 'year']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "E3IUCpoQVbOw",
        "outputId": "09708cb7-219e-4ca2-ed08-6a2f54d3d361"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['1987', '28th', 'a', 'about', 'accomplishments', 'achievements',\n",
              "       'across', 'activities', 'also', 'an',\n",
              "       ...\n",
              "       'want', 'was', 'way', 'we', 'welfare', 'what', 'where', 'wonder',\n",
              "       'worldwide', 'year'],\n",
              "      dtype='object', length=128)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting Next Word\n",
        "import numpy as np\n",
        "bigran_matrix = np.array(df)\n",
        "target_word = 'science'\n",
        "\n",
        "def Find_next_word_MLE(matrix, s, target_word):\n",
        "  target_row = matrix[df.index.to_list().index(target_word), :]\n",
        "  max_index = np.argmax(target_row)\n",
        "  return df.index.to_list()[max_index]\n",
        "\n",
        "for target_word in s.split():\n",
        "  next_word = Find_next_word_MLE(bigran_matrix, s, target_word)\n",
        "  print (f\"{target_word} --> {next_word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BDXA6u_SLaK6",
        "outputId": "613c36a6-67bc-452c-98a7-b00444a6c6be"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "national --> science\n",
            "science --> day\n",
            "day --> is\n",
            "is --> celebrated\n",
            "celebrated --> across\n",
            "on --> science\n",
            "28th --> february\n",
            "february --> every\n",
            "every --> year\n",
            "year --> the\n",
            "the --> objectives\n",
            "day --> is\n",
            "is --> celebrated\n",
            "to --> commemorate\n",
            "commemorate --> the\n",
            "the --> objectives\n",
            "famous --> indian\n",
            "indian --> physicist\n",
            "physicist --> sir\n",
            "sir --> cv\n",
            "cv --> ramans\n",
            "ramans --> discovery\n",
            "discovery --> of\n",
            "of --> celebrating\n",
            "the --> objectives\n",
            "raman --> effect\n",
            "effect --> moreover\n",
            "moreover --> science\n",
            "science --> day\n",
            "day --> is\n",
            "is --> celebrated\n",
            "a --> day\n",
            "day --> is\n",
            "where --> people\n",
            "people --> can\n",
            "can --> also\n",
            "learn --> about\n",
            "about --> science\n",
            "science --> day\n",
            "and --> a\n",
            "its --> impact\n",
            "impact --> on\n",
            "on --> science\n",
            "our --> lives\n",
            "lives --> it\n",
            "it --> can\n",
            "can --> also\n",
            "also --> be\n",
            "be --> a\n",
            "a --> day\n",
            "way --> to\n",
            "to --> commemorate\n",
            "get --> children\n",
            "children --> excited\n",
            "excited --> about\n",
            "about --> science\n",
            "science --> day\n",
            "and --> a\n",
            "what --> they\n",
            "they --> might\n",
            "might --> want\n",
            "want --> to\n",
            "to --> commemorate\n",
            "do --> in\n",
            "in --> english\n",
            "the --> objectives\n",
            "future --> on\n",
            "on --> science\n",
            "science --> day\n",
            "day --> is\n",
            "different --> events\n",
            "events --> worldwide\n",
            "worldwide --> promote\n",
            "promote --> science\n",
            "science --> day\n",
            "and --> a\n",
            "give --> people\n",
            "people --> can\n",
            "the --> objectives\n",
            "opportunity --> to\n",
            "to --> commemorate\n",
            "participate --> in\n",
            "in --> english\n",
            "handson --> experiments\n",
            "experiments --> byjus\n",
            "byjus --> essay\n",
            "essay --> on\n",
            "on --> science\n",
            "science --> day\n",
            "day --> is\n",
            "helps --> us\n",
            "us --> in\n",
            "know --> some\n",
            "some --> notable\n",
            "notable --> achievements\n",
            "achievements --> and\n",
            "and --> a\n",
            "the --> objectives\n",
            "objectives --> of\n",
            "of --> celebrating\n",
            "celebrating --> science\n",
            "science --> day\n",
            "day --> is\n",
            "the --> objectives\n",
            "wonder --> of\n",
            "of --> celebrating\n",
            "science --> day\n",
            "is --> celebrated\n",
            "immeasurable --> and\n",
            "and --> a\n",
            "we --> must\n",
            "must --> respect\n",
            "respect --> the\n",
            "the --> objectives\n",
            "significant --> innovations\n",
            "innovations --> science\n",
            "science --> day\n",
            "day --> is\n",
            "is --> celebrated\n",
            "an --> annual\n",
            "annual --> celebration\n",
            "celebration --> of\n",
            "of --> celebrating\n",
            "science --> day\n",
            "and --> a\n",
            "technology --> in\n",
            "in --> english\n",
            "india --> moreover\n",
            "national --> science\n",
            "science --> day\n",
            "day --> is\n",
            "was --> first\n",
            "first --> observed\n",
            "observed --> in\n",
            "in --> english\n",
            "1987 --> in\n",
            "in --> english\n",
            "india --> moreover\n",
            "moreover --> science\n",
            "science --> day\n",
            "day --> is\n",
            "is --> celebrated\n",
            "celebrated --> across\n",
            "across --> the\n",
            "the --> objectives\n",
            "country --> in\n",
            "in --> english\n",
            "different --> events\n",
            "sectors --> like\n",
            "like --> schools\n",
            "schools --> colleges\n",
            "colleges --> and\n",
            "government --> offices\n",
            "offices --> universities\n",
            "universities --> etc\n",
            "etc --> national\n",
            "national --> science\n",
            "science --> day\n",
            "day --> is\n",
            "is --> celebrated\n",
            "also --> be\n",
            "celebrated --> across\n",
            "in --> english\n",
            "research --> institutes\n",
            "institutes --> medical\n",
            "medical --> colleges\n",
            "colleges --> and\n",
            "and --> a\n",
            "science --> day\n",
            "institutes --> medical\n",
            "now --> let\n",
            "let --> us\n",
            "us --> in\n",
            "learn --> about\n",
            "some --> notable\n",
            "objectives --> of\n",
            "of --> celebrating\n",
            "celebrating --> science\n",
            "science --> day\n",
            "day --> is\n",
            "by --> reading\n",
            "reading --> an\n",
            "an --> annual\n",
            "essay --> on\n",
            "on --> science\n",
            "science --> day\n",
            "day --> is\n",
            "in --> english\n",
            "english --> explains\n",
            "science --> day\n",
            "day --> is\n",
            "is --> celebrated\n",
            "celebrated --> across\n",
            "to --> commemorate\n",
            "spread --> awareness\n",
            "awareness --> and\n",
            "and --> a\n",
            "a --> day\n",
            "message --> about\n",
            "about --> science\n",
            "the --> objectives\n",
            "importance --> of\n",
            "of --> celebrating\n",
            "scientific --> field\n",
            "theories --> and\n",
            "and --> a\n",
            "applications --> in\n",
            "in --> english\n",
            "everyday --> life\n",
            "life --> and\n",
            "science --> day\n",
            "day --> is\n",
            "essay --> on\n",
            "in --> english\n",
            "english --> explains\n",
            "explains --> to\n",
            "to --> commemorate\n",
            "us --> in\n",
            "in --> english\n",
            "brief --> the\n",
            "the --> objectives\n",
            "objectives --> of\n",
            "of --> celebrating\n",
            "celebrating --> science\n",
            "science --> day\n",
            "day --> is\n",
            "the --> objectives\n",
            "objective --> of\n",
            "of --> celebrating\n",
            "celebrating --> science\n",
            "science --> day\n",
            "day --> is\n",
            "is --> celebrated\n",
            "to --> commemorate\n",
            "display --> the\n",
            "the --> objectives\n",
            "efforts --> accomplishments\n",
            "accomplishments --> and\n",
            "and --> a\n",
            "activities --> in\n",
            "in --> english\n",
            "the --> objectives\n",
            "scientific --> field\n",
            "field --> for\n",
            "for --> human\n",
            "human --> welfare\n",
            "welfare --> moreover\n",
            "moreover --> science\n",
            "science --> day\n",
            "enthusiasts --> and\n",
            "and --> a\n",
            "scientists --> discuss\n",
            "discuss --> theories\n",
            "theories --> and\n",
            "of --> celebrating\n",
            "science --> day\n",
            "in --> english\n",
            "everyday --> life\n",
            "life --> and\n",
            "and --> a\n",
            "methods --> to\n",
            "to --> commemorate\n",
            "improve --> technologies\n",
            "technologies --> 1987\n"
          ]
        }
      ]
    }
  ]
}